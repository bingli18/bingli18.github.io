<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Robotics | AutoAI Lab</title>
    <link>/tag/robotics/</link>
      <atom:link href="/tag/robotics/index.xml" rel="self" type="application/rss+xml" />
    <description>Robotics</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Wed, 25 Aug 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/logo_hufbce6705a566d43a9610d78203895d17_430824_300x300_fit_lanczos_2.png</url>
      <title>Robotics</title>
      <link>/tag/robotics/</link>
    </image>
    
    <item>
      <title>Multi-Scale Fusion With Matching Attention Model: A Novel Decoding Network Cooperated With NAS for Real-Time Semantic Segmentation</title>
      <link>/publication/21-nas-attention-tits/</link>
      <pubDate>Wed, 25 Aug 2021 00:00:00 +0000</pubDate>
      <guid>/publication/21-nas-attention-tits/</guid>
      <description>&lt;p&gt;Abstract:
This paper proposes a real-time multi-scale semantic segmentation network (MsNet). MsNet is a combination of our novel multi-scale fusion with matching attention model (MFMA) as the decoding network and the network searched by asymptotic neural architecture search (ANAS) or MobileNetV3 as the encoding network. The MFMA not only extracts low level spatial features from multi-scale inputs but also decodes the contextual features extracted by ANAS. Specifically, considering the advantages and disadvantages of the addition fusion and concatenation fusion, we design multi-scale fusion (MF) that balances speed and accuracy. Then we creatively design two matching attention mechanisms (MA), including matching attention with low calculation (MALC) mechanism and matching attention with strong global context modeling (MASG) mechanism, to match varying resolutions and information of features at different levels of a network. Besides, the ANAS performs the deep neural network search by employing an asymptotic method and provide an efficient encoding network for MsNet, releasing researchers from those tedious mechanical trials. Through extensive experiments, we prove that MFMA, which can be applied to numerous recognition tasks, possesses excellent decoding ability. And we demonstrate the effectiveness and necessity of implementing the matching attention mechanism. Finally, the proposed two versions, MsNet-ANAS and MsNet-M achieve a new state-of-the-art trade-off between accuracy and speed on the CamVid and Cityscapes datasets. More remarkably, on the Nvidia Tesla V100 GPU, our MsNet-ANAS achieves 74.1% mIoU with the speed of 184.2 FPS on the CamVid while 72.9% mIoU with the speed of 119.9 FPS on the Cityscapes.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>3D Mapping and Stability Prediction for Autonomous Wheelchairs</title>
      <link>/publication/20-wheelchair-stability-cyber/</link>
      <pubDate>Fri, 20 Nov 2020 00:00:00 +0000</pubDate>
      <guid>/publication/20-wheelchair-stability-cyber/</guid>
      <description>&lt;p&gt;Abstract:
Autonomous wheelchairs can address a very large need in many populations by serving as the gateway to a much higher degree of independence and mobility capability. This is due to the fact that the big picture idea for autonomous wheelchairs integration into the transportation chain is to allow for individuals to be able to utilize the Intelligent wheelchair to reach the vehicle (regardless of terrain), mount into autonomous wheelchair that navigates to desired destination, and finally autonomous wheelchair dismounts. This will enable a higher degree of mobility for a handicapped population that experiences a large quantity of restrictions as a result of their circumstances. In order for this potential to be achieved numerous precautions must be integrated into the control system, such as stability maintenance. This paper focuses on mapping the environment through the use of a LiDAR sensor and predicting the stability of the given wheelchair. We utilize RTAB Mapping in combination with LiDAR odometry to construct a 3D map of the environment. Then Poisson reconstruction is deployed to convert the built 3D pointcloud into triangular mesh that allows for the norms to the surface to be calculated, which allows for stability prediction. This paper, not only outlines a novel pipeline but also deployed the pipeline on the recently released Intel RealSense L515 sensor and leverages its unique capabilities.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Semantic Digital Surface Map Towards Collaborative Off-Road Vehicle Autonomy</title>
      <link>/publication/20-gvsets-mapping/</link>
      <pubDate>Thu, 13 Aug 2020 00:00:00 +0000</pubDate>
      <guid>/publication/20-gvsets-mapping/</guid>
      <description>&lt;p&gt;Abstract:
The fundamental aspect of unmanned ground vehicle (UGV) navigation, especially over off-road environments, are representations of terrain describing geometry, types, and traversability. One of the typical representations of the environment is digital surface models (DSMs) which efficiently encode geometric information. In this research, we propose a collaborative approach for UGV navigation through unmanned aerial vehicle (UAV) mapping to create semantic DSMs, by leveraging the UAV wide field of view and nadir perspective for map surveying. Semantic segmentation models for terrain recognition are affected by sensing modality as well as dataset availability. We explored and developed semantic segmentation deep convolutional neural networks (CNN) models to construct semantic DSMs. We further conducted a thorough quantitative and qualitative analysis regarding image modalities (between RGB, RGB+DSM and RG+DSM) and dataset availability effects on the performance of segmentation CNN models.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Dynamic Modeling and Prediction of Rollover Stability for All-Terrain Vehicles</title>
      <link>/publication/20-gvsets-atv-stability/</link>
      <pubDate>Tue, 11 Aug 2020 00:00:00 +0000</pubDate>
      <guid>/publication/20-gvsets-atv-stability/</guid>
      <description>&lt;p&gt;Abstract:
With the particular passage capability, all-terrain vehicle (ATV) has been widely used for off-road scenarios. In this research, we conduct a lateral sway stability analysis for the suspension mechanism of a general vehicle and establish a mathematical model of static and dynamic stability based on the maximum lateral sway angle and lateral sway acceleration, by considering the combined angular stiffness of independent suspension, angular stiffness of the lateral stabilizer bar and vertical stiffness of tires. 3D point cloud data of a terrain environment is collected using an RGB-Depth camera, and a triangular topography map is constructed. The results in ADAMS show that the proposed stability model can accurately predict the critical tipping state of the vehicle, and the method deployed for real-world terrain modeling and simulation analysis is generalizable for the stability assessment of the interaction between ATV and real-world terrain.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Concrete Defects Inspection and 3D Mapping Using CityFlyer Quadrotor Robot</title>
      <link>/publication/20-inspection-drone/</link>
      <pubDate>Mon, 29 Jun 2020 00:00:00 +0000</pubDate>
      <guid>/publication/20-inspection-drone/</guid>
      <description>&lt;p&gt;Abstract:
The concrete aging problem has gained more attention in recent years as more bridges and tunnels in the United States lack proper maintenance. Though the Federal Highway Administration requires these public concrete structures to be inspected regularly, on-site manual inspection by human operators is time-consuming and labor-intensive. Conventional inspection approaches for concrete inspection, using RGB imagebased thresholding methods, are not able to determine metric information as well as accurate location information for assessed defects for conditions. To address this challenge, we propose a deep neural network (DNN) based concrete inspection system using a quadrotor flying robot (referred to as CityFlyer) mounted with an RGB-D camera. The inspection system introduces several novel modules. Firstly, a visual-inertial fusion approach is introduced to perform camera and robot positioning and structure 3D metric reconstruction. The reconstructed map is used to retrieve the location and metric information of the defects. Secondly, we introduce a DNN model, namely AdaNet, to detect concrete spalling and cracking, with the capability of maintaining robustness under various distances between the camera and concrete surface. In order to train the model, we craft a new dataset, i.e., the concrete structure spalling and cracking (CSSC) dataset, which is released publicly to the research community. Finally, we introduce a 3D semantic mapping method using the annotated framework to reconstruct the concrete structure for visualization. We performed comparative studies and demonstrated that our AdaNet can achieve 8.41% higher detection accuracy than ResNets and VGGs. Moreover, we conducted five field tests, of which three are manual hand-held tests and two are drone-based field tests. These results indicate that our system is capable of performing metric field inspection, and can serve as an effective tool for civil engineers.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Predicting Wheelchair Stability While Crossing a Curb Using RGB-Depth Vision</title>
      <link>/publication/20-wheelchair-curb-icchp/</link>
      <pubDate>Fri, 01 May 2020 00:00:00 +0000</pubDate>
      <guid>/publication/20-wheelchair-curb-icchp/</guid>
      <description>&lt;p&gt;Abstract:
Handicapped individuals often rely heavily on various assistive technologies including wheelchairs and the purpose of these technologies is to enable greater levels of independence for the user. In the development of autonomous wheelchairs, it is imperative that the wheelchair maintains appropriate stability for the user in an outdoor urban environment. This paper proposes an RGB-Depth based perception algorithm for 3D mapping of the environment in addition to dynamic modeling of the wheelchair for stability analysis and prediction. We utilize RTAB Mapping in combination with Poisson Reconstruction that produced triangular mesh from which an accurate prediction of the stability of the wheelchair can be made based on the normals and the critical angle calculated from the dynamic model of the wheelchair.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Method, Apparatus and Computer Program Product for Mapping and Modeling a Three Dimensional Structure</title>
      <link>/publication/20-mapping-patent/</link>
      <pubDate>Tue, 21 Jan 2020 00:00:00 +0000</pubDate>
      <guid>/publication/20-mapping-patent/</guid>
      <description>&lt;p&gt;Abstract:
Embodiments described herein may provide a method for generating a three-dimensional vector model of the interior of a structure. Methods may include: receiving sensor data indicative of a trajectory; receiving sensor data defining structural surfaces within a structure; generating a three-dimensional point cloud from the sensor data defining structural surfaces within the structure; segmenting the three-dimensional point cloud into two or more segments based, at least in part, on the sensor data indicative of trajectory; generating a three-dimensional surface model of an interior of the structure based on the segmented three-dimensional point cloud with semantic recognition and labelling; and providing the three-dimensional surface model of an interior of the structure to an advanced driver assistance system to facilitate autonomous vehicle parking.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deep Neural Network based Visual Inspection with 3D Metric Measurement of Concrete Defects using Wall-climbing Robot</title>
      <link>/publication/19-visual-inspection-iros/</link>
      <pubDate>Sun, 03 Nov 2019 00:00:00 +0000</pubDate>
      <guid>/publication/19-visual-inspection-iros/</guid>
      <description>&lt;p&gt;Abstract:
This paper presents a novel metric inspection robot system using a deep neural network to detect and measure surface flaws (i.e., crack and spalling) on concrete structures performed by a wall-climbing robot. The system consists of four modules: robotics data collection module to obtain RGB-D images and IMU measurement, visual-inertial SLAM module to generate pose coupled key-frames with depth information, InspectionNet module to classify each pixel into three classes (back-ground, crack and spalling), and 3D registration and map fusion module to register the flaw patch into registered 3D model overlaid and highlighted with detected flaws for spatial-contextual visualization. The system enables the metric model of each surface flaw patch with pixel-level accuracy and determines its location in 3D space that is significant for structural health assessment and monitoring. The InspectionNet achieves an average accuracy of 87.64% for crack and spalling inspection. We also demonstrate our InspectionNet is robust to view angle, scale and illumination variation. Finally, we design a metric voxel volume map to highlight the flaw in 3D model and provide location and metric information.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Vision-Based Mobile Indoor Assistive Navigation Aid for Blind People</title>
      <link>/publication/19-visual-mobile-navi-tmc/</link>
      <pubDate>Fri, 01 Mar 2019 00:00:00 +0000</pubDate>
      <guid>/publication/19-visual-mobile-navi-tmc/</guid>
      <description>&lt;p&gt;Abstract:
This paper presents a new holistic vision-based mobile assistive navigation system to help blind and visually impaired people with indoor independent travel. The system detects dynamic obstacles and adjusts path planning in real-time to improve navigation safety. First, we develop an indoor map editor to parse geometric information from architectural models and generate a semantic map consisting of a global 2D traversable grid map layer and context-aware layers. By leveraging the visual positioning service (VPS) within the Google Tango device, we design a map alignment algorithm to bridge the visual area description file (ADF) and semantic map to achieve semantic localization. Using the on-board RGB-D camera, we develop an efficient obstacle detection and avoidance approach based on a time-stamped map Kalman filter (TSM-KF) algorithm. A multi-modal human-machine interface (HMI) is designed with speech-audio interaction and robust haptic interaction through an electronic SmartCane. Finally, field experiments by blindfolded and blind subjects demonstrate that the proposed system provides an effective tool to help blind individuals with indoor navigation and wayfinding.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An Adaptive Stair-ascending Gait Generation Approach Based on Depth Camera for Lower Limb Exoskeleton.” Review of Scientific Instruments</title>
      <link>/publication/19-depth-gait/</link>
      <pubDate>Wed, 16 Jan 2019 00:00:00 +0000</pubDate>
      <guid>/publication/19-depth-gait/</guid>
      <description>&lt;p&gt;Abstract:
The mobility on stairways is a daily challenge for seniors and people with dyskinesia. Lower limb exoskeletons can be effective assistants to improve their life quality. In this paper, we present an adaptive stair-ascending gait generation algorithm based on a depth camera for lower limb exoskeletons. We first construct a linked-list-based stairway model with the point cloud captured from the depth camera. Then, an optimal foothold point is calculated based on the linked-list stair model for gait generation. Finally, the exoskeleton takes the stair-ascending gait of healthy people as a reference and generates appropriate gait for the stair. The proposed gait generation algorithm is initially validated through holistic simulation analyses. We tested the stairway modeling algorithm on varieties of indoor and outdoor stairways and evaluated the gait generation algorithm on stairs of different height. The subjects’ stair walking tests with lower limb exoskeletons show the effectiveness of the proposed stairway modeling and gait generation approaches.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Semantic Metric 3D Reconstruction for Concrete Inspection</title>
      <link>/publication/18-metric-recon-cvprw/</link>
      <pubDate>Mon, 18 Jun 2018 00:00:00 +0000</pubDate>
      <guid>/publication/18-metric-recon-cvprw/</guid>
      <description>&lt;p&gt;Abstract:
In this paper, we exploit the concrete surface flaw inspection through the fusion of visual positioning and semantic segmentation approach. The fused inspection result is represented by a 3D metric map with a spatial area, width, and depth information, which shows the advantage over general inspection in image space without metric info. We also relieve the human labor with an automatic labeling approach. The system is composed of three hybrid parts: visual positioning to enable pose association, crack/spalling inspection using a deep neural network (pixel level), and a 3D random field filter for fusion to achieve a global 3D metric map. To improve the infrastructure inspection, we released a new data set for concrete crack and spalling segmentation which is built on CSSC dataset [27]. To leverage the effectiveness of the large-scale SLAM aided semantic inspection, we performed three field tests and one baseline test. Experimental results show that our proposed approach significantly improves the capability of 3D metric concrete inspection via deploying visual SLAM. Furthermore, we achieve an 82.4% MaxF1 score for crack detection and 88.64% MaxF1 score for spalling detection on the relabeled dataset.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Collaborative Mapping and Autonomous Parking for Multi-Story Parking Garage</title>
      <link>/publication/18-colla-mapping-tits/</link>
      <pubDate>Wed, 07 Mar 2018 00:00:00 +0000</pubDate>
      <guid>/publication/18-colla-mapping-tits/</guid>
      <description>&lt;p&gt;Abstract:
We present a novel collaborative mapping and autonomous parking system for semi-structured multi-story parking garages, based on cooperative 3-D LiDAR point cloud registration and Bayesian probabilistic updating. First, an inertial-enhanced (IE) generalized iterative closest point (G-ICP) approach is presented to perform high accuracy registration for LiDAR odometry, which is loosely coupled with inertial measurement unit using multi-state extended Kalman filter fusion. Second, the IE G-ICP is utilized to reconstruct the 3-D point cloud model for each vehicle, and then the individual model maps are merged and updated into a global probabilistic 2-D grid map. A collaborative multiple layer semantic map is constructed to support autonomous parking. Finally, we propose a collaborative navigation approach for path planning when there are multiple vehicles in the parking garage through vehicle-to-vehicle communication. A global path planner is designed to explore the minimum cost path based on the semantic map, and local motion planning is performed using a random exploring algorithm for obstacle avoidance and path smoothing. Our pilot experimental evaluation provides a proof of concept for indoor autonomous parking by collaborative perception, map merging, and updating methodologies.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Random Multi-trajectory Generation Method for Online Emergency Threat Management (Analysis and Application in Path Planning Algorithm)</title>
      <link>/publication/17-multi-traj-path-plan/</link>
      <pubDate>Wed, 20 Dec 2017 00:00:00 +0000</pubDate>
      <guid>/publication/17-multi-traj-path-plan/</guid>
      <description>&lt;p&gt;Abstract:
This paper presents a novel randomized path planning algorithm, which is a goal and homology biased sampling based algorithm called Multiple Guiding Attraction based Random Tree, and robots can use it to tackle pop-up and moving threats under kinodynamic constraints. Our proposed method considers the kinematics and dynamics constraints, using obstacle information to perform informed sampling and redistribution around collision region toward valid routing. We pioneeringly propose a multiple path planning method using ‘Extending Forbidden’ algorithm, rather than using variant cost principles for online threat management. The threat management method performs online path switching between the planned multiple paths, which is proved with better time performance than conventional approaches. The proposed method has advantage in exploration in obstacle crowded environment, where narrow corridor fails using the general sampling based exploration methods. We perform detailed comparative experiments with peer approaches in cluttered environment, and point out the advantages in time and mission performance.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An Assistive Indoor Navigation System for the Visually Impaired in Multi-Floor Environments (Best Conference Paper Award)</title>
      <link>/publication/17-indoor-navi-cyber/</link>
      <pubDate>Tue, 01 Aug 2017 00:00:00 +0000</pubDate>
      <guid>/publication/17-indoor-navi-cyber/</guid>
      <description>&lt;p&gt;Abstract:
This paper presents an innovative wearable system to assist visually impaired people navigate indoors in real time. Our proposed system incorporates state-of-the-art handheld devices from Google&amp;rsquo;s Project Tango and integrates path planner and obstacle avoidance submodules, as well as human-computer interaction techniques, to provide assistance to the user. Our system preprocesses a priori knowledge of the environment extracted from CAD files and spatial information from Google&amp;rsquo;s Area Description Files. The system can then reallocate resources to navigation and human-computer interaction tasks during execution. The system is capable of exploring complex environments spanning multiple floors and has been tested and demonstrated in a variety of indoor environments.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Rise-Rover: A Wall-Climbing Robot with High Reliability and Load-Carrying Capacity (Industrial Robot Innovation Award)</title>
      <link>/publication/15-wall-climbing-clawar/</link>
      <pubDate>Mon, 31 Jul 2017 00:00:00 +0000</pubDate>
      <guid>/publication/15-wall-climbing-clawar/</guid>
      <description>&lt;p&gt;Abstract:
This paper presents Rise-Rover, a new generation wall-climbing robot with high reliability and load-carrying capacity on vertical surfaces for Non-Destructive Testing (NDT) of concrete and steel infrastructure. One Rise-Rover drivetrain module can operate on both smooth and rough vertical/inclined surfaces independently. The on-board electronics and PID controller monitor the pressure reading and adjust impeller speed to provide stable suction force for the wall-climbing robot. The use of duct fan and tether further increase the operation reliability. Rise-Rover is remotely controlled by Android smartphone via Wifi, and the User Interface (UI) provides good usability and convenience. The experimental test verified the good performance of the Rise-Rover prototype.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Wall-climbing Robot for Non-destructive Evaluation using Impact-echo and Metric Learning SVM</title>
      <link>/publication/17-wall-climbing-inspection/</link>
      <pubDate>Mon, 31 Jul 2017 00:00:00 +0000</pubDate>
      <guid>/publication/17-wall-climbing-inspection/</guid>
      <description>&lt;p&gt;Abstract:
The impact-echo (IE) acoustic inspection method is a non-destructive evaluation technique, which has been widely applied to detect the defects, structural deterioration level, and thickness of plate-like concrete structures. This paper presents a novel climbing robot, namely Rise-Rover, to perform automated IE signal collection from concrete structures with IE signal analyzing based on machine learning techniques. Rise-Rover is our new generation robot, and it has a novel and enhanced absorption system to support heavy load, and crawler-like suction cups to maintain high mobility performance while crossing small grooves. Moreover, the design enables a seamless transition between ground and wall. This paper applies the fast Fourier transform and wavelet transform for feature detection from collected IE signals. A distance metric learning based support vector machine approach is newly proposed to automatically classify the IE signals. With the visual-inertial odometry of the robot, the detected flaws of inspection area on the concrete plates are visualized in 2D/3D. Field tests on a concrete bridge deck demonstrate the efficiency of the proposed robot system in automatic health condition assessment for concrete structures.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Wearable Indoor Navigation System with Context-based Decision Making For Visually Impaired</title>
      <link>/publication/16-wearable-navi-sys/</link>
      <pubDate>Tue, 15 Nov 2016 00:00:00 +0000</pubDate>
      <guid>/publication/16-wearable-navi-sys/</guid>
      <description>&lt;p&gt;Abstract:
This paper presents a wearable indoor navigation system that helps visually impaired user to perform indoor navigation. The system takes advantage of the Simultaneous Localization and Mapping (SLAM) and semantic path planning to accomplish localization and navigation tasks while collaborating with the visually impaired user. It integrates multiple sensors and feedback devices as an RGB-D camera, an IMU and a web camera; and it applies the RGB-D based visual odometry algorithm to estimate the user&amp;rsquo;s location and orientation, and uses the IMU to refine the orientation error. Major landmarks such as room numbers and corridor corners are detected by the web camera and RGB-D camera, and matched to the digitalized floor map so as to localize the user. The path and motion guidance are generated afterwards to guide the user to a desired destination. To improve the fitting between the rigid commands and optimal machine decisions for human beings, we propose a context based decision making mechanism on path planning that resolves users&amp;rsquo; confusions caused by incorrect observations. The software modules are implemented in Robotics Operating System (ROS) and the navigation system are tested with blindfolded sight persons. The field experiments confirm the feasibility of the system prototype and the proposed mechanism.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tension Distribution Algorithm of a 7-DOF Cable-Driven Robotic Arm Based on Dynamic Minimum Pre-Tightening Force</title>
      <link>/publication/11-robotic-arm-robio/</link>
      <pubDate>Wed, 07 Dec 2011 00:00:00 +0000</pubDate>
      <guid>/publication/11-robotic-arm-robio/</guid>
      <description>&lt;p&gt;Abstract:
From shoulder to wrist, a person&amp;rsquo;s arm has a total of seven degrees of freedom (DOFs), which is the minimum number of DOF for the robot that needs to avoid obstacles and internal singularity. Compared to the traditional 7-DOF robot, the 7-DOF cable-driven robotic arm (CDRA) similar to human muscles parallel drive mode is the hybrid structure of serial-parallel, which possesses a number of promising advantages, such as simple and light-weight mechanical structure, high-loading capacity, and large reachable workspace. Since the cable can only generate tension and cannot stand pressure, cable-driven mechanism must be a redundant drive structure. Both the shoulder and wrist joint are redundant drive mechanism, and the tension of four cables has multiple solutions in the same posture. Hence, iteration Newton-Euler method is adopted to conduct dynamic analysis. Cable tension distribution algorithm based on null space method by solving Pseudo-inverse matrix is proposed, and in order to keep the cable tensional and also reduce energy consumption, the index of dynamic minimum pre-tightening force is originally proposed to realtime adjust the driving force of each cable. To show the accuracy and effectiveness of the proposed cable tension distribution algorithm, several simulation results are illustrated. These lay a good theory foundation for further research on effective control and performance improvement of the CDRA.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Construction and Realization of a 3D Perceptual System Based on 2D Laser Radar</title>
      <link>/publication/08-perceptual-sys-iciea/</link>
      <pubDate>Thu, 05 Jun 2008 00:00:00 +0000</pubDate>
      <guid>/publication/08-perceptual-sys-iciea/</guid>
      <description>&lt;p&gt;Abstract:
This paper presents a 3D perceptual system based on 2D laser radar LMS291. The proposed system utilizes intelligent module to add a degree of freedom to LMS291. A new method of synchronization between LMS291 and intelligent module was proposed. We added Visual C++ multi-media timer to the timestamp method, the purpose we use this method is to change the level resolution conveniently, and control the number of the points we acquired, because in some condition we need speedy scanning to rebuild the reconstructed image of the terrain quickly. And we use Matlab to reconstruct the 2D and 3D images. To repair the singular points we selected absolute mean value method. The experiment shows that absolute mean value method works more accurately and effectively And this system we designed can be used for image reconstruction in unstructured environment by experiments.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>3D Reconstruction Embedded System Based on Laser Scanner for Mobile Robot</title>
      <link>/publication/08-3d-recon-iciea/</link>
      <pubDate>Tue, 03 Jun 2008 00:00:00 +0000</pubDate>
      <guid>/publication/08-3d-recon-iciea/</guid>
      <description>&lt;p&gt;Abstract:
For 3D reconstruction technology based on laser ranging for mobile robot, this paper presents the design of real-time embedded system for 3D data processing. Firstly, this paper introduces the home and abroad research situation of laser ranging for mobile robot, and analysis the method of 3D data acquisition with 2D laser scanner and ID driving motor module. Secondly, this paper introduces the hardware design and system building of multi-module embedded system, which consists of DSP data acquisition module, FPGA data processing module and ARM control. The ARM system is the main control system and realizes 3D reconstruction function. CAN bus communication is selected between these modules. Thirdly, this paper introduces the design of communication programming under ARM control system. At last, this paper presents the 3D reconstruction method with laser scanner and driving motor by Mesa3D based on RTLinux system.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
