<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Johnell Brooks | AutoAI Lab</title>
    <link>/author/johnell-brooks/</link>
      <atom:link href="/author/johnell-brooks/index.xml" rel="self" type="application/rss+xml" />
    <description>Johnell Brooks</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 22 Aug 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/logo_hufbce6705a566d43a9610d78203895d17_430824_300x300_fit_lanczos_2.png</url>
      <title>Johnell Brooks</title>
      <link>/author/johnell-brooks/</link>
    </image>
    
    <item>
      <title>Passenger Vehicle Preferences, Challenges, and Opportunities for Users Who Are Visually Impaired: An Exploratory Study</title>
      <link>/publication/22-seewayuser-bjvi/</link>
      <pubDate>Mon, 22 Aug 2022 00:00:00 +0000</pubDate>
      <guid>/publication/22-seewayuser-bjvi/</guid>
      <description>&lt;p&gt;Abstract:
Individuals with visual impairments encounter many obstacles with passenger vehicles. This study aimed to increase the understanding of challenges specifically related to vehicles including ingress, in-vehicle considerations, comfort, and acceptance of ridesharing and transportation options for individuals who are visually impaired. Ten participants who are visually impaired, with an average age of 57.5 years, completed a semi-structured interview. The interview took place over Zoom or over the phone and focused on their passenger vehicle preferences and challenges, as well as what they would want for them to look like in the future. All of the participants typically requested rides from family and friends for local transportation, while only two used rideshare services. Half of the participants described the most common challenge when getting into a vehicle as hitting oneâ€™s head. All of the participants used their sense of touch to locate the seat belt, and most used touch and hearing to locate the vehicle and door they were getting into. When asked what they would like in the future for broader transportation needs, examples ranged from a talking cane, to an electronic guide dog, or to ear buds that could provide directions. Throughout the interviews, participants expressed the importance of transportation for them. This study increased the understanding of the challenges used when walking from an indoor environment to get to and into a vehicle. Understanding how individuals who are visually impaired currently get to and into a vehicle may aid engineers, new technology developers and O&amp;amp;M providers to create more processes and/or training that can help increase transportation options for those who are visually impaired.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SeeWay: Vision-Language Assistive Navigation for the Visually Impaired</title>
      <link>/publication/22-seeway-smc/</link>
      <pubDate>Mon, 03 Jan 2022 00:00:00 +0000</pubDate>
      <guid>/publication/22-seeway-smc/</guid>
      <description>&lt;p&gt;Abstract:
Assistive navigation for blind or visually impaired (BVI) individuals is of significance to extend their mobility and safety in traveling, enhancing their employment opportunities and fostering personal fulfillment. Conventional research is mainly based on robotic navigation approaches through localization, mapping, and path planning frameworks. They require heavy manual annotation of semantic information in maps and its alignment with sensor mapping. Inspired by the fact that we human beings naturally rely on language instruction inquiry and visual scene understanding to navigate in an unfamiliar environment, this paper proposes a novel vision-language model-based approach for BVI navigation. It does not need heavy-labeled indoor maps and provides a Safe and Efficient E-Wayfinding (SeeWay) assistive solution for BVI individuals. The system consists of a scene-graph map construction module, a navigation path generation module for global path inference by vision-language navigation (VLN), and a navigation with obstacle avoidance module for real-time local navigation. The SeeWay system was deployed on portable iPhone devices with cloud computing assistance for the VLN model inference. The field tests show the effectiveness of the VLN global path finding and local path re-planning. Experiments and quantitative results reveal that heuristic-style instruction outperforms direction/detailed-style instructions for VLN success rate (SR), and the SR decreases as the navigation length increases.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
